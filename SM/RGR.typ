#import "@preview/modern-g7-32:0.2.0": abstract, appendix-heading, appendixes, enum-numbering, gost

#set enum(numbering: enum-numbering)

#show: gost.with(
  ministry: "Наименование министерства (ведомства) или другого структурного образования, в систему которого входит организация-исполнитель",
  organization: (
    full: "Полное наименование организации — исполнителя НИР",
    short: "Сокращённое наименование организации",
  ),
  udk: "индекс УДК",
  research-number: "регистрационный номер НИР",
  report-number: "регистрационный номер отчета",
  approved-by: (
    name: "Фамилия И.О.",
    position: "Должность, наимен. орг.",
    year: 2017,
  ), // Гриф согласования
  agreed-by: (
    name: "Фамилия И.О.",
    position: "Должность, наимен. орг.",
    year: auto,
  ), // Гриф утверждения, год подставляется из аргумента year
  report-type: "отчёт",
  about: "О научно-исследовательской работе",
  research: "Наименование НИР",
  bare-subject: false, // Можно убрать "по теме"
  subject: "Наименование отчёта",
  manager: (
    name: "Фамилия И.О.",
    position: "Должность",
    title: "Руководитель НИР,",
  ), // Руководитель отчёта
  stage: (type: "вид отчёта", num: 1), // Этап отчёта
  federal: "Наименование федеральной программы",
  part: 2, // Номер книги отчёта
  city: "Город",
  year: auto, // Можно поменять год, auto - текущий год
  text-size: (default: 14pt, small: 10pt), // Можно указать размеры текста
  indent: 1.25cm, // Можно указать отступ
  hide-title: true, // Убрать ли титульный лист
  title-footer-align: center, // Выравнивание города и года на титульном листе
  pagination-align: center, // Выравнивание номера страницы
  margin: (
    left: 30mm,
    right: 15mm,
    top: 20mm,
    bottom: 20mm,
  ), // Отступы страницы
  add-pagebreaks: false, // Убрать ли разрывы страниц
)

#outline()

#pagebreak()

= Введение
Настоящий отчёт посвящён выполнению расчётно-графической работы по теме "Работа с онлайн-инструментами для исследователя". Цель работы — освоить современные онлайн-инструменты для ведения исследовательской деятельности, создания и размещения публикаций, а также получить практический опыт их использования для решения реальных задач.

Мои научные интересы связаны с темой диссертации: разработка подходов к генерации синтетических обучающих данных для нейронных сетей. 

= Сравнение баз научных работ

- *Elibrary*

Функциональность: Специализированная платформа для отслеживания российской публикационной активности, интегрированная с системой аттестации научных кадров. Имеет развитые инструменты для анализа научных метрик (индекс Хирша, импакт-факторы журналов РИНЦ). Поисковые возможности и интерфейс уступают международным аналогам.

Охват / Содержательность: Охват практически исчерпывающий для русскоязычных публикаций (диссертации, статьи в российских журналах, монографии). Однако для заданной темы это является ключевым ограничением: основная масса передовых исследований в области синтетических данных и машинного обучения публикуется на английском языке в международных изданиях. В РИНЦ много узкоспециализированных работ, ориентированных на локальные задачи, но общий объем и новизна контента по теме существенно отстают от мировых трендов.
  
- *Google Scholar*

Функциональность: Упрощенный, но мощный бесплатный поиск по широкому спектру источников. Отличная функция отслеживания цитирований и создания профилей авторов. Критическим недостатком является отсутствие строгой фильтрации по качеству источников, так как индекс включает как рецензируемые статьи, так и препринты, слайды, диссертации и материалы с низкокачественных сайтов.

Охват / Содержательность: Наиболее широкий охват среди всех рассмотренных систем. Индексирует контент из журналов, репозиториев (включая arXiv), университетских сайтов и других баз данных. По запросам, связанным с «synthetic data generation neural networks», выдает сотни тысяч результатов, обеспечивая максимальную полноту. Многие уникальные материалы (технические отчеты, препринты) можно найти только здесь.


- *arXiv*

Функциональность:
arXiv - это открытый репозиторий препринтов с фокусом на физику, математику и компьютерные науки. Поиск не самый удобный (основан на категориях и ключевых словах), но сообщество поддерживает AI-инструменты для анализа и суммаризации статей (например, alphaXiv). Доступ полностью бесплатный, с возможностью подписки на обновления по категориям (cs.LG, cs.CV, cs.CL). Нет встроенных наукометрических инструментов, но препринты часто цитируются в других базах.

Содержательность и охват: Исключительно высокая ценность для актуальных исследований в ML. Категории cs.LG (машинное обучение), cs.CV (компьютерное зрение), cs.CL (обработка естественного языка) содержат тысячи препринтов по генерации синтетических данных. Здесь публикуются основополагающие и новаторские работы до их официального рецензирования.

- *ScienceDirect*

Функциональность: Профессиональная платформа с расширенными фильтрами (по типу статьи, журналу), AI-функциями (Topic Pages). Интегрирован сервис PlumX metrix для анализа метрик цитируемости. Работает по модели подписки, что ограничивает доступ, но значительная часть статей доступна в открытом доступе.

Охват / Содержательность: Охват высококачественных рецензируемых журнальных статей издательства Elsevier (журналы по компьютерным наукам, AI, нейросетям). Предоставляет доступ к структурированным обзорам и исследованиям, прошедшим строгое рецензирование. Контент междисциплинарен, охватывает приложения синтетических данных в медицине, биологии и др.

- *SpringerLink* 

Функциональность: Аналогична ScienceDirect: мощные фильтры, доступ по подписке с элементами открытого доступа, наличик сервиса для анализа метрик цитируемости. Отличается сильным акцентом на книжные серии, конференционные труды и архивные коллекции.

Охват / Содержательность: Обеспечивает доступ к обширной коллекции рецензируемых журналов, книг и трудов конференций издательства Springer Nature. Важной особенностью является наличие фундаментальных монографий и сборников, которые служат всесторонними введениями в область (например, книги серии «Synthetic Data for Deep Learning»).


= Подбор и анализ научных статей


1) *Comprehensive Exploration of Synthetic Data Generation: A Survey*

*Авторы: *André Bauer, Simon Trapp, Michael Stenger, Robert Leppich, Samuel Kounev, Mark Leznik, Kyle Chard, Ian Foster

*Место публикации:* arXiv

*Даты публикации:*
- v1. 04.01.2024  
- v2. 01.02.2024

*Cодержание:*
Обзор 417 моделей генерации синтетических данных за последнее десятилетие. Работа охватывает типы моделей, функциональность и применение. Исследование показывает преобладание подходов на основе нейронных сетей, доминирование компьютерного зрения с GAN как основными генеративными моделями, а также растущую роль диффузионных моделей, трансформеров и RNN. Авторы подчеркивают нехватку общих метрик и датасетов для сравнения, а также необходимость учета вычислительных затрат.

*Комментарий:*
Обзорная статья, которая даёт хорошее представление о всём поле синтетических данных. Статья полезна для получения общей картины и понимания различных подходов. 


2) *Generative Adversarial Networks for Synthetic Data Generation in Deep Learning Applications*

*Автор: *M. Keskes

*Место публикации:* Journal of Artificial Intelligence Research and Innovation

*Дата публикации:* 05.09.2025

*Cодержание:*
Комплексный анализ роли GAN в создании высококачественных синтетических данных в различных областях, включая здравоохранение, финансы, компьютерное зрение и обработку естественного языка. Работа исследует базовые принципы GAN, продвинутые архитектуры (DCGAN, cGAN, CycleGAN, TimeGAN) и их применение для генерации медицинских изображений, финансовых временных рядов и табличных данных. Обсуждаются преимущества GAN, такие как сохранение приватности и эффективность по затратам, наряду с ограничениями, включая нестабильность обучения и отсутствие стандартизированных метрик оценки.

*Комментарий:*
ГАНы стали одной из классических моделей для генерации данных, имитирующие реальные. Они способны моделировать самые разные модальности. Разве что текстовые данные им плохо поддаются.


3) *Synthetic Data Generation by Diffusion Models*

*Автор: *Jun Zhu

*Место публикации:* National Science Review

*Дата публикации:* 24.08.2024

*Cодержание:*
Краткий обзор диффузионных моделей, которые применяются для генерации многомерных данных, включая изображения, 3D-контент. Диффузионные модели широко используются для моделирования распределения данных непрерывной области благодаря стабильности обучения и сильной модельной емкости. Помимо изображений, диффузионные модели применяются для генерации данных в различных областях: речь, 3D-объекты, движения человека, видео и молекулы.

*Комментарий:*
Небольшая статья, которая рассказывает о концепции диффузионных моделей и их применении.

4) *Machine Learning for Synthetic Data Generation: A Review*

*Автор: *Yingzhou Lu, Lulu Chen, Yuanyuan Zhang, Minjie Shen, Huazheng Wang, Xiao Wang, Capucine van Rechem, Tianfan Fu, Wenqi Wei

*Место публикации:* arXiv

*Дата публикации:* 

- v1. 08.02.2023

  ...
- v10. 04.04.2025

*Cодержание:*
Обзор существующих исследований, использующих модели машинного обучения для генерации синтетических данных. Работа анализирует различные подходы к генерации синтетических данных с применением методов машинного обучения, включая методы для траекторий, временных рядов и других типов данных. Особое внимание уделяется методам, обеспечивающим дифференциальную приватность.

*Комментарий:*
Статья подробно рассматривает применение синтетических данных в разных сферах, а также генеративные модели, способные их создавать.

5) *Synthetic Data and Artificial Neural Networks for Natural Scene Text Recognition*

*Авторы: *Max Jaderberg, Karen Simonyan, Andrea Vedaldi, Andrew Zisserman

*Место публикации:* arXiv

*Даты публикации:* 
- v1. 09.06.2014

  ...
- v4. 09.12.2014

*Cодержание:*
Приложение синтетической генерации данных к обучению нейросетей для распознавания текста в естественных сценах. Исследуются методы создания реалистичных синтетических текстовых изображений для обучения моделей распознавания без обширной ручной аннотации. Демонстрирует, что синтетические данные значительно улучшают производительность модели в сценариях с ограниченными ресурсами.


6) *Synthetic Data Generation Using Large Language Models: Advances in Text and Code*

*Авторы: * Mihai Nadas, Laura Diosan, Andreea Tomescu

*Место публикации:* IEEE Access

*Дата публикации:* 15 июля 2025

*Cодержание:* Обзор о том, как большие языковые модели трансформируют синтетическую генерацию обучающих данных в сферах естественного языка и кода. Статья охватывает выдающиеся подходы, включая аугментацию данных, выполняемую с помощью промптов, поиск с увеличением контекста (RAG), методы само-инструктирования (self-instruct) и обучение с подкреплением обратной связью. Систематически анализирует техники, приложения, вызовы и будущие направления.

*Комментарий:* 
Статья подробно рассматривает различные техники генерации текстовых данных, приводя статьи-примеры применение этих техник. 


7) *The Curious Decline of Linguistic Diversity: Training Language Models on Synthetic Text*

*Автор: * Yanzhu Guo, Guokan Shang, Michalis Vazirgiannis, Chloé Clavel

*Место публикации:* NAACL

*Дата публикации:* 29.05.2024

*Cодержание:* Исследование последствий обучения языковых моделей на синтетических данных, генерируемых их предшественниками, особенно при рекурсивном применении. Авторы разработали набор метрик, охватывающих лексическое, синтаксическое и семантическое разнообразие. Результаты выявляют последовательное снижение разнообразия выходных данных модели с каждой итерацией, особенно заметное в творческих задачах.

*Комментарий:* Статья наглядно показала, что если использовать для обучения LLM только данные, сгенерированные этой же LLM, то происходит потеря разнообразия генерируемого текста и последующее повторение этой делает все хуже.

8) *Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias*

*Автор: * Yue Yu, Yuchen Zhuang, Jieyu Zhang, Yu Meng, Alexander J Ratner, Ranjay Krishna, Jiaming Shen, Chao Zhang

*Место публикации:* NeurIPS

*Дата публикации:* 10.12.2023

*Cодержание:* Исследование роли больших языковых моделей как генераторов атрибутированных обучающих данных и анализ сложного взаимоотношения между разнообразием и смещением (bias) в сгенерированных датасетах. Статья изучает, как LLM могут одновременно улучшать и потенциально вредить обучению моделей через введение смещений. Предоставляет инсайты в механизмы контроля качества для LLM-генерируемых синтетических данных.

*Комментарий:* В статье предложен интересный способ промтинга LLM, который улучшает качество синтетических данных, хотя он все также не спасает от возможных появлений смещений в этих данных. 


9) *On the Diversity of Synthetic Data and its Impact on Training Large Language Models*

*Автор: * Hao Chen, Abdul Waheed, Xiang Li, Yidong Wang, Jindong Wang, Bhiksha Raj, Marah I. Abdin

*Место публикации:* arXiv

*Даты публикации:* 

- v1. 19.07.2024
- v2. 22.07.2024

*Cодержание:* Исследование влияния разнообразия синтетических данных на производительность LLM на этапах предварительного обучения и fine-tuning. Авторы вводят метрику LLM cluster-agent для оценки разнообразия. Контролируемые эксперименты показывают, что разнообразие синтетических данных при предварительном обучении более значимо влияет на fine-tuning, чем на само предварительное обучение.

*Комментарий:* В статье в очередной раз было показано, что промтинг способен сильно повысить разнообразие получаемых текстов. 

10) *How Good Is Synthetic Data for Social Media Texts? A Study on Fine-Tuning Low-Resource Language Models for Vietnamese*

*Автор: * Luan Thanh Nguyen

*Место публикации:* PACLIC

*Дата публикации:* 12.2024

*Cодержание:* Эта работа представляет LoSo – систему для генерации синтетических текстов социальных сетей на вьетнамском языке. Исследуется проблема создания реалистичных данных для дообучения моделей в условиях дефицита размеченных данных социальных сетей.

*Комментарий:* Кроме основных моделей для генерации текста, в статье также предствлены применения других моделей для оценки стиля полученных данных, для его изменения. Также в статье была представлена интересная метрика Spoken Text Rate, используемая для оценки неформальности текстов.


= Определение влиятельных авторов

В таблице @crng2 указан список влиятельных авторов в теме генерации синтетических данных.

#figure(
  kind: table,
  caption: [Влиятельные авторы в теме генерации синтетических данных],
  table(
  columns: 6,
  align: (x, y) => if x == 0 { left + horizon } else { center + horizon },
  inset: 7pt,
  table.header[Имя атвора][Время работы][Цитиро\u{00AD}ваний][Индекс h][Индекс i10][Ссылка на профиль],
  [Ian\ Goodfellow],[11 лет],[93172],[101],[185],[#link("https://scholar.google.com/citations?user=iYN86KEAAAAJ&hl=en&oi=ao")[Нажмите, чтобы перейти]],
  [Mihaela van der Schaar],[11 лет],[43887],[95],[600],[#link("https://scholar.google.com/citations?user=iVLAQysAAAAJ&hl=en")[Нажмите, чтобы перейти]],
  [Yejin Choi],[18 лет],[80421],[128],[348],[#link("https://scholar.google.com/citations?user=vhP-tlcAAAAJ")[Нажмите, чтобы перейти]],
  [Jonathan Ho],[12 лет],[76556],[36],[41],[#link("https://scholar.google.com/citations?hl=ru&user=iVLAQysAAAAJ")[Нажмите, чтобы перейти]],
  [Samuli Laine],[9 лет],[60888],[47],[96],[#link("https://scholar.google.com/citations?user=UCXJOTUAAAAJ&hl=en")[Нажмите, чтобы перейти]]),
) <crng2>

= Определение влиятельных изданий

В таблице @crng указаны влиятельные издания в теме генерации синтетических данных.

#figure(
  kind: table,
  caption: [Влиятельные издания в теме генерации синтетических данных],
table(
  columns: 3,
  align: center + horizon,
  inset: 10pt,
table.header[Название издания][Импакт фактор][Индексы],
[Nature Machine Intelligence],[23.9],[Scopus, Web of Science],
[IEEE TPAMI],[18.6],[Scopus, Web of Science],
[Artificial Intelligence Review],[13.9],[Scopus, Web of Science],
[Journal of Machine Learning Research],[5.2],[Scopus, Web of Science],
[Artificial Intelligence (Elsevier)],[4.6],[Scopus, Web of Science]),
) <crng>


= Подбор международных научных конференций

1) *International Conference on Machine Learning and Artificial Intelligence Applications*

Сайт конференции: https://isit.org.in/event/index.php?id=100059060

Место проведения: Казань

Даты проведения конференции: 27 - 28 февраля 2026

Крайний срок подачи асбтракта: 7 февраля 2026

2) *International Conference on Artificial Intelligence, Machine Learning and Technology*

Сайт конференции: https://sciencecite.com/event/index.php?id=3376407

Место проведения: Санкт-Петербург

Даты проведения конференции: 27-28 января 2026

Крайний срок подачи текста статьи: 12 января 2026

3) *International Conference of Young Professionals in Electron Devices and Materials*

Сайт конференции: https://edm.ieeesiberia.org/

Место проведения: Республика Алтай

Даты проведения конференции: 27 июня - 1 июля 2026

Крайний срок подачи текста статьи: 19 марта 2026

4) *International Conference on Artificial Intelligence, Deep Learning and Machine Learning* 

Сайт конференции: https://iser.co/Conference/27162/ICAIDLML/

Место проведения: Санкт-Петербург

Даты проведения конференции: 9-10 апреля 2026 

Крайний срок подачи текста статьи: 25 марта 2026

5) *International Conference on AI and Data Science Innovation*

Сайт конференции: https://igaeglobal.com/conf/index.php?id=100643919

Место проведения: Москва

Даты проведения конференции: 27 - 28 мая 2026

Крайний срок подачи асбтракта: 2 мая 2026


Самой интересной для меня является International Conference of Young Professionals in Electron Devices and Materials, поскольку данная конференция единственная из приведенного списка имеет поддержку крупной организации, хотя её направленность не полностью совпадает с моими научными интересами.


= Заключение

В ходе РГР освоены онлайн-инструменты, проведено сравнение баз, подобраны материалы, авторы и конференции, произведена регистрация на ResearchGate.



